{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from utilities import create_data as create\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "home_dir = os.path.join(os.path.expanduser('~'), 'Documents/TDT4173-ML')\n",
    "saved_data_path = os.path.join(home_dir, 'data_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create.CreateData()\n",
    "\n",
    "train = data.create_training_data(use_mean_values=True)\n",
    "test = data.create_test_data(use_mean_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absolute_humidity_2m:gm3              0\n",
      "air_density_2m:kgm3                   0\n",
      "ceiling_height_agl:m              16417\n",
      "clear_sky_energy_1h:J                 0\n",
      "clear_sky_rad:W                       0\n",
      "cloud_base_agl:m                   6738\n",
      "dew_or_rime:idx                       0\n",
      "dew_point_2m:K                        0\n",
      "diffuse_rad:W                         0\n",
      "diffuse_rad_1h:J                      0\n",
      "direct_rad:W                          0\n",
      "direct_rad_1h:J                       0\n",
      "effective_cloud_cover:p               0\n",
      "elevation:m                           0\n",
      "fresh_snow_12h:cm                     0\n",
      "fresh_snow_1h:cm                      0\n",
      "fresh_snow_24h:cm                     0\n",
      "fresh_snow_3h:cm                      0\n",
      "fresh_snow_6h:cm                      0\n",
      "is_day:idx                            0\n",
      "is_in_shadow:idx                      0\n",
      "msl_pressure:hPa                      0\n",
      "precip_5min:mm                        0\n",
      "precip_type_5min:idx                  0\n",
      "pressure_100m:hPa                     0\n",
      "pressure_50m:hPa                      0\n",
      "prob_rime:p                           0\n",
      "rain_water:kgm2                       0\n",
      "relative_humidity_1000hPa:p           0\n",
      "sfc_pressure:hPa                      0\n",
      "snow_depth:cm                         0\n",
      "snow_drift:idx                        0\n",
      "snow_melt_10min:mm                    0\n",
      "snow_water:kgm2                       0\n",
      "sun_azimuth:d                         0\n",
      "sun_elevation:d                       0\n",
      "super_cooled_liquid_water:kgm2        0\n",
      "t_1000hPa:K                           0\n",
      "total_cloud_cover:p                   0\n",
      "visibility:m                          0\n",
      "wind_speed_10m:ms                     0\n",
      "wind_speed_u_10m:ms                   0\n",
      "wind_speed_v_10m:ms                   0\n",
      "wind_speed_w_1000hPa:ms               0\n",
      "pv_measurement                        0\n",
      "dtype: int64\n",
      "date_calc                           0\n",
      "absolute_humidity_2m:gm3            0\n",
      "air_density_2m:kgm3                 0\n",
      "ceiling_height_agl:m              570\n",
      "clear_sky_energy_1h:J               0\n",
      "clear_sky_rad:W                     0\n",
      "cloud_base_agl:m                  223\n",
      "dew_or_rime:idx                     0\n",
      "dew_point_2m:K                      0\n",
      "diffuse_rad:W                       0\n",
      "diffuse_rad_1h:J                    0\n",
      "direct_rad:W                        0\n",
      "direct_rad_1h:J                     0\n",
      "effective_cloud_cover:p             0\n",
      "elevation:m                         0\n",
      "fresh_snow_12h:cm                   0\n",
      "fresh_snow_1h:cm                    0\n",
      "fresh_snow_24h:cm                   0\n",
      "fresh_snow_3h:cm                    0\n",
      "fresh_snow_6h:cm                    0\n",
      "is_day:idx                          0\n",
      "is_in_shadow:idx                    0\n",
      "msl_pressure:hPa                    0\n",
      "precip_5min:mm                      0\n",
      "precip_type_5min:idx                0\n",
      "pressure_100m:hPa                   0\n",
      "pressure_50m:hPa                    0\n",
      "prob_rime:p                         0\n",
      "rain_water:kgm2                     0\n",
      "relative_humidity_1000hPa:p         0\n",
      "sfc_pressure:hPa                    0\n",
      "snow_depth:cm                       0\n",
      "snow_drift:idx                      0\n",
      "snow_melt_10min:mm                  0\n",
      "snow_water:kgm2                     0\n",
      "sun_azimuth:d                       0\n",
      "sun_elevation:d                     0\n",
      "super_cooled_liquid_water:kgm2      0\n",
      "t_1000hPa:K                         0\n",
      "total_cloud_cover:p                 0\n",
      "visibility:m                        0\n",
      "wind_speed_10m:ms                   0\n",
      "wind_speed_u_10m:ms                 0\n",
      "wind_speed_v_10m:ms                 0\n",
      "wind_speed_w_1000hPa:ms             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(train.isna().sum())\n",
    "print(test.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    92951.000000\n",
       "mean       287.232321\n",
       "std        766.670114\n",
       "min         -0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%        173.362500\n",
       "max       5733.420000\n",
       "Name: pv_measurement, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = 'pv_measurement'\n",
    "train[label].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231107_144530/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231107_144530/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #37~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Mon Oct  9 15:34:04 UTC 2\n",
      "Disk Space Avail:   170.61 GB / 250.38 GB (68.1%)\n",
      "Train Data Rows:    92951\n",
      "Train Data Columns: 44\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (5733.42, -0.0, 287.23232, 766.67011)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tAvailable Memory:                    2205.57 MB\n",
      "\tTrain Data (Original)  Memory Usage: 16.36 MB (0.7% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 44 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 44 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t0.3s = Fit runtime\n",
      "\t44 features in original data used to generate 44 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 16.36 MB (0.7% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.29s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.026895891383632235, Train Rows: 90451, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\tWarning: Potentially not enough memory to safely train model. Estimated to require 0.057 GB out of 2.279 GB available memory (12.571%)... (20.000% of avail memory is the max safe size)\n",
      "\tTo avoid this warning, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=0.22 to avoid the warning)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t-664.5504\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t0.49s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\tWarning: Potentially not enough memory to safely train model. Estimated to require 0.057 GB out of 2.307 GB available memory (12.423%)... (20.000% of avail memory is the max safe size)\n",
      "\tTo avoid this warning, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=0.22 to avoid the warning)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t-807.1167\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t0.43s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 238.777\n",
      "[2000]\tvalid_set's rmse: 233.532\n",
      "[3000]\tvalid_set's rmse: 231.595\n",
      "[4000]\tvalid_set's rmse: 230.355\n",
      "[5000]\tvalid_set's rmse: 229.676\n",
      "[6000]\tvalid_set's rmse: 229.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-229.5822\t = Validation score   (-root_mean_squared_error)\n",
      "\t24.06s\t = Training   runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 229.417\n",
      "[2000]\tvalid_set's rmse: 223.085\n",
      "[3000]\tvalid_set's rmse: 219.985\n",
      "[4000]\tvalid_set's rmse: 217.978\n",
      "[5000]\tvalid_set's rmse: 216.719\n",
      "[6000]\tvalid_set's rmse: 215.36\n",
      "[7000]\tvalid_set's rmse: 214.404\n",
      "[8000]\tvalid_set's rmse: 213.825\n",
      "[9000]\tvalid_set's rmse: 213.227\n",
      "[10000]\tvalid_set's rmse: 212.906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-212.9053\t = Validation score   (-root_mean_squared_error)\n",
      "\t37.36s\t = Training   runtime\n",
      "\t1.43s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 184 due to low memory. Expected memory usage reduced from 24.35% -> 15.0% of available memory...\n",
      "\t-242.8661\t = Validation score   (-root_mean_squared_error)\n",
      "\t105.98s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-216.3435\t = Validation score   (-root_mean_squared_error)\n",
      "\t173.41s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 149 due to low memory. Expected memory usage reduced from 30.19% -> 15.0% of available memory...\n",
      "\t-241.9145\t = Validation score   (-root_mean_squared_error)\n",
      "\t20.35s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-250.0031\t = Validation score   (-root_mean_squared_error)\n",
      "\t58.24s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-227.7264\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.83s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-256.8049\t = Validation score   (-root_mean_squared_error)\n",
      "\t52.45s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 214.97\n",
      "[2000]\tvalid_set's rmse: 209.228\n",
      "[3000]\tvalid_set's rmse: 207.53\n",
      "[4000]\tvalid_set's rmse: 206.8\n",
      "[5000]\tvalid_set's rmse: 206.216\n",
      "[6000]\tvalid_set's rmse: 205.921\n",
      "[7000]\tvalid_set's rmse: 205.672\n",
      "[8000]\tvalid_set's rmse: 205.517\n",
      "[9000]\tvalid_set's rmse: 205.442\n",
      "[10000]\tvalid_set's rmse: 205.373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-205.3733\t = Validation score   (-root_mean_squared_error)\n",
      "\t73.97s\t = Training   runtime\n",
      "\t2.52s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-205.055\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.19s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 572.04s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231107_144530/\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=label).fit(train_data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_forecast\n",
       "2023-05-01 00:00:00     -1.510917\n",
       "2023-05-01 01:00:00     -0.930792\n",
       "2023-05-01 02:00:00     -1.094912\n",
       "2023-05-01 03:00:00     44.515774\n",
       "2023-05-01 04:00:00    253.171509\n",
       "Name: pv_measurement, dtype: float32"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = TabularDataset(test)\n",
    "\n",
    "y_pred = predictor.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "predictions = pd.DataFrame(y_pred)\n",
    "predictions.reset_index(inplace=True)\n",
    "predictions.drop(columns=['date_forecast'], inplace=True)\n",
    "\n",
    "# Set all negative values to zero\n",
    "predictions[predictions < 0] = 0\n",
    "\n",
    "predictions.to_csv(os.path.join(saved_data_path, '07E_autogluon_mean.csv'), index=True, index_label='id', header=['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import create_delivery_file as delivery\n",
    "\n",
    "file = delivery.CreateDelivery(y_pred, '07E_autogluon_mean.csv')\n",
    "file.create_delivery_file(use_aggregated_values=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
