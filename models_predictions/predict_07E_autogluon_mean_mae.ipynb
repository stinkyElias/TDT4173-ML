{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from utilities import create_data as create\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "home_dir = os.path.join(os.path.expanduser('~'), 'Documents/TDT4173-ML')\n",
    "saved_data_path = os.path.join(home_dir, 'data_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create.CreateData()\n",
    "\n",
    "train = data.create_training_data(use_mean_values=True)\n",
    "test = data.create_test_data(use_mean_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absolute_humidity_2m:gm3              0\n",
      "air_density_2m:kgm3                   0\n",
      "ceiling_height_agl:m              16417\n",
      "clear_sky_energy_1h:J                 0\n",
      "clear_sky_rad:W                       0\n",
      "cloud_base_agl:m                   6738\n",
      "dew_or_rime:idx                       0\n",
      "dew_point_2m:K                        0\n",
      "diffuse_rad:W                         0\n",
      "diffuse_rad_1h:J                      0\n",
      "direct_rad:W                          0\n",
      "direct_rad_1h:J                       0\n",
      "effective_cloud_cover:p               0\n",
      "elevation:m                           0\n",
      "fresh_snow_12h:cm                     0\n",
      "fresh_snow_1h:cm                      0\n",
      "fresh_snow_24h:cm                     0\n",
      "fresh_snow_3h:cm                      0\n",
      "fresh_snow_6h:cm                      0\n",
      "is_day:idx                            0\n",
      "is_in_shadow:idx                      0\n",
      "msl_pressure:hPa                      0\n",
      "precip_5min:mm                        0\n",
      "precip_type_5min:idx                  0\n",
      "pressure_100m:hPa                     0\n",
      "pressure_50m:hPa                      0\n",
      "prob_rime:p                           0\n",
      "rain_water:kgm2                       0\n",
      "relative_humidity_1000hPa:p           0\n",
      "sfc_pressure:hPa                      0\n",
      "snow_depth:cm                         0\n",
      "snow_drift:idx                        0\n",
      "snow_melt_10min:mm                    0\n",
      "snow_water:kgm2                       0\n",
      "sun_azimuth:d                         0\n",
      "sun_elevation:d                       0\n",
      "super_cooled_liquid_water:kgm2        0\n",
      "t_1000hPa:K                           0\n",
      "total_cloud_cover:p                   0\n",
      "visibility:m                          0\n",
      "wind_speed_10m:ms                     0\n",
      "wind_speed_u_10m:ms                   0\n",
      "wind_speed_v_10m:ms                   0\n",
      "wind_speed_w_1000hPa:ms               0\n",
      "pv_measurement                        0\n",
      "dtype: int64\n",
      "date_calc                           0\n",
      "absolute_humidity_2m:gm3            0\n",
      "air_density_2m:kgm3                 0\n",
      "ceiling_height_agl:m              570\n",
      "clear_sky_energy_1h:J               0\n",
      "clear_sky_rad:W                     0\n",
      "cloud_base_agl:m                  223\n",
      "dew_or_rime:idx                     0\n",
      "dew_point_2m:K                      0\n",
      "diffuse_rad:W                       0\n",
      "diffuse_rad_1h:J                    0\n",
      "direct_rad:W                        0\n",
      "direct_rad_1h:J                     0\n",
      "effective_cloud_cover:p             0\n",
      "elevation:m                         0\n",
      "fresh_snow_12h:cm                   0\n",
      "fresh_snow_1h:cm                    0\n",
      "fresh_snow_24h:cm                   0\n",
      "fresh_snow_3h:cm                    0\n",
      "fresh_snow_6h:cm                    0\n",
      "is_day:idx                          0\n",
      "is_in_shadow:idx                    0\n",
      "msl_pressure:hPa                    0\n",
      "precip_5min:mm                      0\n",
      "precip_type_5min:idx                0\n",
      "pressure_100m:hPa                   0\n",
      "pressure_50m:hPa                    0\n",
      "prob_rime:p                         0\n",
      "rain_water:kgm2                     0\n",
      "relative_humidity_1000hPa:p         0\n",
      "sfc_pressure:hPa                    0\n",
      "snow_depth:cm                       0\n",
      "snow_drift:idx                      0\n",
      "snow_melt_10min:mm                  0\n",
      "snow_water:kgm2                     0\n",
      "sun_azimuth:d                       0\n",
      "sun_elevation:d                     0\n",
      "super_cooled_liquid_water:kgm2      0\n",
      "t_1000hPa:K                         0\n",
      "total_cloud_cover:p                 0\n",
      "visibility:m                        0\n",
      "wind_speed_10m:ms                   0\n",
      "wind_speed_u_10m:ms                 0\n",
      "wind_speed_v_10m:ms                 0\n",
      "wind_speed_w_1000hPa:ms             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(train.isna().sum())\n",
    "print(test.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    92951.000000\n",
       "mean       287.232321\n",
       "std        766.670114\n",
       "min         -0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%        173.362500\n",
       "max       5733.420000\n",
       "Name: pv_measurement, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = 'pv_measurement'\n",
    "train[label].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231107_151714/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231107_151714/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #37~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Mon Oct  9 15:34:04 UTC 2\n",
      "Disk Space Avail:   169.72 GB / 250.38 GB (67.8%)\n",
      "Train Data Rows:    92951\n",
      "Train Data Columns: 44\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (5733.42, -0.0, 287.23232, 766.67011)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1196.19 MB\n",
      "\tTrain Data (Original)  Memory Usage: 16.36 MB (1.4% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 44 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 44 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t0.5s = Fit runtime\n",
      "\t44 features in original data used to generate 44 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 16.36 MB (1.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.53s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.026895891383632235, Train Rows: 90451, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 0.057 GB out of 1.220 GB available memory (23.486%)... (20.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=0.28 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\tNot enough memory to train KNeighborsUnif... Skipping this model.\n",
      "Fitting model: KNeighborsDist ...\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 0.057 GB out of 1.221 GB available memory (23.466%)... (20.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=0.28 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\tNot enough memory to train KNeighborsDist... Skipping this model.\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 87.0696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-86.7391\t = Validation score   (-mean_absolute_error)\n",
      "\t9.51s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 80.0957\n",
      "[2000]\tvalid_set's l1: 77.73\n",
      "[3000]\tvalid_set's l1: 76.405\n",
      "[4000]\tvalid_set's l1: 75.4039\n",
      "[5000]\tvalid_set's l1: 74.9988\n",
      "[6000]\tvalid_set's l1: 74.4863\n",
      "[7000]\tvalid_set's l1: 74.0625\n",
      "[8000]\tvalid_set's l1: 73.912\n",
      "[9000]\tvalid_set's l1: 73.6997\n",
      "[10000]\tvalid_set's l1: 73.6092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-73.6089\t = Validation score   (-mean_absolute_error)\n",
      "\t50.53s\t = Training   runtime\n",
      "\t2.12s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 94 due to low memory. Expected memory usage reduced from 47.7% -> 15.0% of available memory...\n",
      "\t-81.0636\t = Validation score   (-mean_absolute_error)\n",
      "\t75.88s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-77.4579\t = Validation score   (-mean_absolute_error)\n",
      "\t283.27s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 140 due to low memory. Expected memory usage reduced from 32.09% -> 15.0% of available memory...\n",
      "\t-81.8543\t = Validation score   (-mean_absolute_error)\n",
      "\t27.29s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-91.6384\t = Validation score   (-mean_absolute_error)\n",
      "\t70.19s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-82.122\t = Validation score   (-mean_absolute_error)\n",
      "\t14.2s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-81.5796\t = Validation score   (-mean_absolute_error)\n",
      "\t155.22s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 72.894\n",
      "[2000]\tvalid_set's l1: 69.9319\n",
      "[3000]\tvalid_set's l1: 69.0202\n",
      "[4000]\tvalid_set's l1: 68.4728\n",
      "[5000]\tvalid_set's l1: 68.1079\n",
      "[6000]\tvalid_set's l1: 67.9428\n",
      "[7000]\tvalid_set's l1: 67.7653\n",
      "[8000]\tvalid_set's l1: 67.6615\n",
      "[9000]\tvalid_set's l1: 67.5998\n",
      "[10000]\tvalid_set's l1: 67.5582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-67.5582\t = Validation score   (-mean_absolute_error)\n",
      "\t77.59s\t = Training   runtime\n",
      "\t2.85s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-67.1822\t = Validation score   (-mean_absolute_error)\n",
      "\t0.15s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 775.05s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231107_151714/\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=label, eval_metric='mean_absolute_error').fit(train_data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = TabularDataset(test)\n",
    "\n",
    "y_pred = predictor.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "predictions = pd.DataFrame(y_pred)\n",
    "predictions.reset_index(inplace=True)\n",
    "predictions.drop(columns=['date_forecast'], inplace=True)\n",
    "\n",
    "# Set all negative values to zero\n",
    "predictions[predictions < 0] = 0\n",
    "\n",
    "predictions.to_csv(os.path.join(saved_data_path, '07E_autogluon_mean_mae.csv'), index=True, index_label='id', header=['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'as_data_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_42919/1119827793.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutilities\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_delivery_file\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdelivery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelivery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCreateDelivery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'07E_autogluon_mean.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_delivery_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_aggregated_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/TDT4173-ML/models_predictions/../utilities/create_delivery_file.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, use_aggregated_values)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_delivery_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_aggregated_values\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \"\"\"\n\u001b[1;32m     29\u001b[0m         \u001b[0mCreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdelivery\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msaves\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mresults\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcsv\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \"\"\"\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_H2O_to_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_negative_values_to_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_aggregated_values\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/TDT4173-ML/models_predictions/../utilities/create_delivery_file.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;34m-\u001b[0m \u001b[0mA\u001b[0m \u001b[0mPandas\u001b[0m \u001b[0mDataFrame\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mH2OFrame\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \"\"\"\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mH2O_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_data_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5898\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5899\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5900\u001b[0m         ):\n\u001b[1;32m   5901\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5902\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'as_data_frame'"
     ]
    }
   ],
   "source": [
    "from utilities import create_delivery_file as delivery\n",
    "\n",
    "file = delivery.CreateDelivery(y_pred, '07E_autogluon_mean.csv')\n",
    "file.create_delivery_file(use_aggregated_values=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
