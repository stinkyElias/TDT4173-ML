{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "import pandas as pd\n",
    "import utilities as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405151\n"
     ]
    }
   ],
   "source": [
    "data_list = utils.read_data()\n",
    "Data = utils.DataProcessor(data_list)\n",
    "\n",
    "df = Data.create_train_data()\n",
    "df.sort_index(inplace=True)\n",
    "# df.drop('pv_measurement', axis=1)\n",
    "\n",
    "df_all = df.copy()\n",
    "df_no_snow = df.copy()\n",
    "df_feat_no_snow = df.copy()\n",
    "\n",
    "df_no_snow = df[utils.get_features(3)]\n",
    "df_feat_no_snow = df[utils.get_features(4)]\n",
    "\n",
    "X_train_all = df_all[~df['pv_measurement'].isna()]\n",
    "\n",
    "# Print length of df_all\n",
    "print(len(df_all))\n",
    "\n",
    "X_train_all = df_all.drop('pv_measurement', axis=1)\n",
    "X_train_no_snow = df_no_snow.drop('pv_measurement', axis=1)\n",
    "X_train_feat_no_snow = df_feat_no_snow.drop('pv_measurement', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405151\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Feature selection with no NaNs\n",
    "print(len(X_train_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # train = pd.concat([self.A_train, self.B_train, self.C_train], axis=0)\n",
    "        # target = pd.concat([self.A_target, self.B_target, self.C_target], axis=0)\n",
    "\n",
    "        # for df in [train, target]:\n",
    "        #     df.sort_index(inplace=True)\n",
    "       \n",
    "        # if features == 'all':\n",
    "        #     FEATURES = list(train.columns)\n",
    "        # elif features == 'no_snow':\n",
    "        #     FEATURES = get_features(3)\n",
    "        # elif features == 'feat_no_snow':\n",
    "        #     FEATURES = get_features(4)\n",
    "\n",
    "        # # Remove column 'pv_measurement' from features\n",
    "        # FEATURES.remove('pv_measurement')\n",
    "        # TARGET = ['pv_measurement']\n",
    "\n",
    "        # X_train = train[FEATURES]\n",
    "        # y_train = train[TARGET]\n",
    "\n",
    "        # # In both X_train and y_train, we have to remove the rows where pv_measurement is NaN but keep building\n",
    "        # if nans == 'remove':\n",
    "        #     X_train = X_train[~y_train['pv_measurement'].isna()]\n",
    "        #     y_train = y_train[~y_train['pv_measurement'].isna()]\n",
    "\n",
    "        # # Fill NaN values with 0\n",
    "        # elif nans == 'fill_0':\n",
    "        #     X_train.fillna(0, inplace=True)\n",
    "        #     y_train.fillna(0, inplace=True)\n",
    "        \n",
    "        # # Fill NaN values with LSTM predictions\n",
    "        # elif nans == 'fill_LSTM':\n",
    "        #     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'date_forecast'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'date_forecast'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/stinky/Documents/ntnu/ml/TDT4173-ML/test_and_train_file_creator.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/stinky/Documents/ntnu/ml/TDT4173-ML/test_and_train_file_creator.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Feature selection with no NaNs\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/stinky/Documents/ntnu/ml/TDT4173-ML/test_and_train_file_creator.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df_all \u001b[39m=\u001b[39m Data_0\u001b[39m.\u001b[39mcreate_train_data()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/stinky/Documents/ntnu/ml/TDT4173-ML/test_and_train_file_creator.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df_no_snow \u001b[39m=\u001b[39m Data_1\u001b[39m.\u001b[39;49mcreate_train_data()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/stinky/Documents/ntnu/ml/TDT4173-ML/test_and_train_file_creator.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m df_feat_no_snow \u001b[39m=\u001b[39m Data_2\u001b[39m.\u001b[39mcreate_train_data()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/stinky/Documents/ntnu/ml/TDT4173-ML/test_and_train_file_creator.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m df_all\u001b[39m.\u001b[39msort_index(inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/ntnu/ml/TDT4173-ML/utilities.py:28\u001b[0m, in \u001b[0;36mDataProcessor.create_train_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mB_train \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mB_obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mB_est\u001b[39m.\u001b[39miloc[:, \u001b[39m1\u001b[39m:]], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mC_train \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mC_obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mC_est\u001b[39m.\u001b[39miloc[:, \u001b[39m1\u001b[39m:]], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_format_time_index()\n\u001b[1;32m     30\u001b[0m \u001b[39m# add the target column to the training data\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mA_train[\u001b[39m'\u001b[39m\u001b[39mpv_measurement\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mA_target[\u001b[39m'\u001b[39m\u001b[39mpv_measurement\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/ntnu/ml/TDT4173-ML/utilities.py:42\u001b[0m, in \u001b[0;36mDataProcessor._format_time_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_format_time_index\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     40\u001b[0m     \u001b[39m# convert the date_forecast column to a datetime object and set it as the index\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     \u001b[39mfor\u001b[39;00m df \u001b[39min\u001b[39;00m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mA_train, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mB_train, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mC_train, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mA_test, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mB_test, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mC_test]:\n\u001b[0;32m---> 42\u001b[0m         df[\u001b[39m'\u001b[39m\u001b[39mdate_forecast\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(df[\u001b[39m'\u001b[39;49m\u001b[39mdate_forecast\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     43\u001b[0m         df\u001b[39m.\u001b[39mset_index(\u001b[39m'\u001b[39m\u001b[39mdate_forecast\u001b[39m\u001b[39m'\u001b[39m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     44\u001b[0m     \u001b[39m# convert the time column to a datetime object and set it as the index\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'date_forecast'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# # Save the train data to csv file in the folder feature_selection/no_NaNs\n",
    "# X_train_all.to_csv('feature_selection/no_NaNs/train_data_all_features.csv')\n",
    "# X_train_no_snow.to_csv('feature_selection/no_NaNs/train_data_no_snow_features.csv')\n",
    "# X_train_feat_no_snow.to_csv('feature_selection/no_NaNs/train_data_feat_no_snow_features.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_0 = Data_0.create_test_data()\n",
    "X_test_1 = Data_1.create_test_data()\n",
    "X_test_2 = Data_2.create_test_data()\n",
    "# Keep only the columns that are in the train data\n",
    "X_test_all = X_test_0[X_train_all.columns]\n",
    "X_test_no_snow = X_test_0[X_train_no_snow.columns]\n",
    "X_test_feat_no_snow = X_test_0[X_train_feat_no_snow.columns]\n",
    "\n",
    "# Print number of rows with NaNs\n",
    "print('all features: ', X_test_all.isnull().any(axis=1).sum())\n",
    "print('no snow features: ', X_test_no_snow.isnull().any(axis=1).sum())\n",
    "print('feat no snow features: ', X_test_feat_no_snow.isnull().any(axis=1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the test data to csv file in the folder feature_selection\n",
    "# X_test.to_csv('feature_selection/no_NaNs/test_data_all_featurewiz_without_snow.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = df['pv_measurement']\n",
    "# y_train.to_csv('feature_selection/no_NaNs/y_train.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
